{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatterbox Turbo TTS Debugging Notebook\n",
    "\n",
    "This notebook helps debug Chatterbox Turbo TTS audio generation issues.\n",
    "\n",
    "**Run on Google Colab with GPU enabled:**\n",
    "- Runtime → Change runtime type → GPU (T4 is sufficient)\n",
    "\n",
    "**You will need:**\n",
    "- Hugging Face token with read access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q chatterbox-tts huggingface-hub torchaudio matplotlib librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass(\"Enter your Hugging Face token: \")\n",
    "login(token=hf_token)\n",
    "print(\"Authenticated with Hugging Face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio as ta\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Chatterbox Turbo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatterbox.tts_turbo import ChatterboxTurboTTS\n",
    "\n",
    "print(\"Loading Chatterbox Turbo TTS model...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ChatterboxTurboTTS.from_pretrained(device=device)\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Sample rate: {model.sr} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_audio(wav, sr, title=\"Audio Waveform\"):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    if isinstance(wav, torch.Tensor):\n",
    "        wav_np = wav.cpu().numpy().squeeze()\n",
    "    else:\n",
    "        wav_np = wav.squeeze()\n",
    "    \n",
    "    axes[0].plot(wav_np)\n",
    "    axes[0].set_title(f\"{title} - Waveform\")\n",
    "    axes[0].set_xlabel(\"Sample\")\n",
    "    axes[0].set_ylabel(\"Amplitude\")\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(wav_np)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[1])\n",
    "    axes[1].set_title(f\"{title} - Spectrogram\")\n",
    "    fig.colorbar(img, ax=axes[1], format=\"%+2.0f dB\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Duration: {len(wav_np) / sr:.2f}s\")\n",
    "    print(f\"Shape: {wav_np.shape}\")\n",
    "    print(f\"Amplitude: [{wav_np.min():.4f}, {wav_np.max():.4f}]\")\n",
    "    print(f\"Mean: {wav_np.mean():.4f}, Std: {wav_np.std():.4f}\")\n",
    "\n",
    "def play_audio(wav, sr):\n",
    "    if isinstance(wav, torch.Tensor):\n",
    "        wav_np = wav.cpu().numpy().squeeze()\n",
    "    else:\n",
    "        wav_np = wav.squeeze()\n",
    "    display(Audio(wav_np, rate=sr))\n",
    "\n",
    "def save_audio(wav, sr, filename):\n",
    "    ta.save(filename, wav.cpu() if isinstance(wav, torch.Tensor) else wav, sr)\n",
    "    print(f\"Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test 1: Simple Text with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, this is a test.\"\n",
    "print(f\"Text: {text}\")\n",
    "print(\"Using default parameters\")\n",
    "\n",
    "wav = model.generate(text)\n",
    "\n",
    "visualize_audio(wav, model.sr, \"Test 1: Default Parameters\")\n",
    "play_audio(wav, model.sr)\n",
    "save_audio(wav, model.sr, \"test1_default.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test 2: Simple Text with Your Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, this is a test.\"\n",
    "print(f\"Text: {text}\")\n",
    "print(\"Using: exaggeration=0.5, cfg_weight=0.5\")\n",
    "\n",
    "wav = model.generate(text, exaggeration=0.5, cfg_weight=0.5, temperature=1.0)\n",
    "\n",
    "visualize_audio(wav, model.sr, \"Test 2: Your Parameters\")\n",
    "play_audio(wav, model.sr)\n",
    "save_audio(wav, model.sr, \"test2_your_params.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test 3: Check Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "signature = inspect.signature(model.generate)\n",
    "print(\"ChatterboxTurboTTS.generate() signature:\")\n",
    "print(signature)\n",
    "print(\"\\nParameters:\")\n",
    "for param_name, param in signature.parameters.items():\n",
    "    default = param.default if param.default != inspect.Parameter.empty else \"required\"\n",
    "    print(f\"  {param_name}: {default}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test 4: Different Parameter Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "tests = [\n",
    "    {\"name\": \"Default\", \"params\": {}},\n",
    "    {\"name\": \"Low_exaggeration\", \"params\": {\"exaggeration\": 0.5}},\n",
    "    {\"name\": \"High_exaggeration\", \"params\": {\"exaggeration\": 1.5}},\n",
    "    {\"name\": \"Low_CFG\", \"params\": {\"cfg_weight\": 0.3}},\n",
    "    {\"name\": \"High_CFG\", \"params\": {\"cfg_weight\": 0.9}},\n",
    "    {\"name\": \"Your_params\", \"params\": {\"exaggeration\": 0.5, \"cfg_weight\": 0.5}},\n",
    "]\n",
    "\n",
    "for i, test in enumerate(tests, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Test {i}: {test['name']}\")\n",
    "    print(f\"Parameters: {test['params']}\")\n",
    "    \n",
    "    wav = model.generate(text, **test['params'])\n",
    "    \n",
    "    filename = f\"test4_{test['name']}.wav\"\n",
    "    save_audio(wav, model.sr, filename)\n",
    "    play_audio(wav, model.sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test 5: Preprocessed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    lines = text.split('\\n')\n",
    "    paragraphs = []\n",
    "    current = []\n",
    "    \n",
    "    for line in lines:\n",
    "        cleaned = line.strip()\n",
    "        if not cleaned:\n",
    "            if current:\n",
    "                paragraphs.append(' '.join(current))\n",
    "                current = []\n",
    "        else:\n",
    "            current.append(cleaned)\n",
    "    \n",
    "    if current:\n",
    "        paragraphs.append(' '.join(current))\n",
    "    \n",
    "    result = '\\n\\n'.join(paragraphs)\n",
    "    return re.sub(r' +', ' ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"We loitered the morning away in the garden. Stanley Hopkins had\n",
    "      gone down to the village to look into some rumours of a strange\n",
    "      woman who had been seen by some children on the Chatham Road.\"\"\"\n",
    "\n",
    "cleaned = preprocess_text(raw_text)\n",
    "\n",
    "print(\"Raw text:\")\n",
    "print(repr(raw_text[:100]))\n",
    "print(\"\\nCleaned text:\")\n",
    "print(repr(cleaned[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating with cleaned text...\")\n",
    "wav_clean = model.generate(cleaned, exaggeration=0.5, cfg_weight=0.5)\n",
    "save_audio(wav_clean, model.sr, \"test5_cleaned.wav\")\n",
    "play_audio(wav_clean, model.sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating with raw text...\")\n",
    "wav_raw = model.generate(raw_text, exaggeration=0.5, cfg_weight=0.5)\n",
    "save_audio(wav_raw, model.sr, \"test5_raw.wav\")\n",
    "play_audio(wav_raw, model.sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test 6: Short Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Hello.\",\n",
    "    \"This is a test.\",\n",
    "    \"The weather is nice today.\",\n",
    "]\n",
    "\n",
    "for i, s in enumerate(sentences, 1):\n",
    "    print(f\"\\nTest {i}: {s}\")\n",
    "    wav = model.generate(s, exaggeration=0.5, cfg_weight=0.5)\n",
    "    save_audio(wav, model.sr, f\"test6_short_{i}.wav\")\n",
    "    play_audio(wav, model.sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Diagnostic Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTIC QUESTIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Does Test 1 sound good?\")\n",
    "print(\"   YES = Default parameters work\")\n",
    "print(\"   NO = Model issue\")\n",
    "print(\"\")\n",
    "print(\"2. Does Test 2 sound good?\")\n",
    "print(\"   YES = Your parameters are fine\")\n",
    "print(\"   NO = Parameters too low\")\n",
    "print(\"\")\n",
    "print(\"3. Which Test 4 sounds best?\")\n",
    "print(\"   Use those parameters!\")\n",
    "print(\"\")\n",
    "print(\"4. Test 5: Cleaned better than raw?\")\n",
    "print(\"   YES = Preprocessing helps\")\n",
    "print(\"   NO = Not a preprocessing issue\")\n",
    "print(\"\")\n",
    "print(\"5. Are Test 6 short sentences clear?\")\n",
    "print(\"   YES but long text bad = Length issue\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. List Generated Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "files = sorted(glob.glob(\"test*.wav\"))\n",
    "print(f\"Generated {len(files)} test files:\\n\")\n",
    "for f in files:\n",
    "    size = os.path.getsize(f) / 1024\n",
    "    print(f\"  {f} ({size:.1f} KB)\")\n",
    "print(\"\\nDownload from file browser on left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
