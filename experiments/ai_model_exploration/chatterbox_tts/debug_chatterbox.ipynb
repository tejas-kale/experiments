{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatterbox Turbo TTS Debugging Notebook\n",
    "\n",
    "This notebook helps debug Chatterbox Turbo TTS audio generation issues.\n",
    "\n",
    "**Run on Google Colab with GPU enabled:**\n",
    "- Runtime → Change runtime type → GPU (T4 is sufficient)\n",
    "\n",
    "**You'll need:**\n",
    "- Hugging Face token with read access to `ResembleAI/chatterbox-turbo`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q chatterbox-tts huggingface-hub torchaudio matplotlib librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Hugging Face\n",
    "from huggingface_hub import login\n",
    "from getpass import getpass\n",
    "\n",
    "# Enter your HF token when prompted\n",
    "hf_token = getpass(\"Enter your Hugging Face token: \")\n",
    "login(token=hf_token)\n",
    "print(\"✓ Authenticated with Hugging Face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchaudio as ta\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "import io\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Chatterbox Turbo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try loading Chatterbox Turbo\n",
    "from chatterbox.tts_turbo import ChatterboxTurboTTS\n",
    "\n",
    "print(\"Loading Chatterbox Turbo TTS model...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ChatterboxTurboTTS.from_pretrained(device=device)\n",
    "print(f\"✓ Model loaded on {device}\")\n",
    "print(f\"Sample rate: {model.sr} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_audio(wav, sr, title=\"Audio Waveform\"):\n",
    "    \"\"\"Visualize audio waveform and spectrogram.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Convert to numpy if tensor\n",
    "    if isinstance(wav, torch.Tensor):\n",
    "        wav_np = wav.cpu().numpy().squeeze()\n",
    "    else:\n",
    "        wav_np = wav.squeeze()\n",
    "    \n",
    "    # Waveform\n",
    "    axes[0].plot(wav_np)\n",
    "    axes[0].set_title(f\"{title} - Waveform\")\n",
    "    axes[0].set_xlabel(\"Sample\")\n",
    "    axes[0].set_ylabel(\"Amplitude\")\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Spectrogram\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(wav_np)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', ax=axes[1])\n",
    "    axes[1].set_title(f\"{title} - Spectrogram\")\n",
    "    fig.colorbar(img, ax=axes[1], format=\"%+2.0f dB\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Audio stats\n",
    "    print(f\"Audio duration: {len(wav_np) / sr:.2f} seconds\")\n",
    "    print(f\"Audio shape: {wav_np.shape}\")\n",
    "    print(f\"Min amplitude: {wav_np.min():.4f}\")\n",
    "    print(f\"Max amplitude: {wav_np.max():.4f}\")\n",
    "    print(f\"Mean amplitude: {wav_np.mean():.4f}\")\n",
    "    print(f\"Std amplitude: {wav_np.std():.4f}\")\n",
    "\n",
    "def play_audio(wav, sr):\n",
    "    \"\"\"Play audio in notebook.\"\"\"\n",
    "    if isinstance(wav, torch.Tensor):\n",
    "        wav_np = wav.cpu().numpy().squeeze()\n",
    "    else:\n",
    "        wav_np = wav.squeeze()\n",
    "    display(Audio(wav_np, rate=sr))\n",
    "\n",
    "def save_audio(wav, sr, filename):\n",
    "    \"\"\"Save audio to file.\"\"\"\n",
    "    ta.save(filename, wav.cpu() if isinstance(wav, torch.Tensor) else wav, sr)\n",
    "    print(f\"✓ Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test 1: Simple Text with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with very simple text\n",
    "text = \"Hello, this is a test.\"\n",
    "print(f\"Generating speech for: '{text}'\")\n",
    "print(\"Using default parameters...\")\n",
    "\n",
    "wav = model.generate(text)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "visualize_audio(wav, model.sr, \"Test 1: Simple Text (Default)\")\n",
    "print(\"\\nPlayback:\")\n",
    "play_audio(wav, model.sr)\n",
    "save_audio(wav, model.sr, \"test1_simple_default.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test 2: Simple Text with Your Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with your parameters (exaggeration=0.5, cfg_weight=0.5)\n",
    "text = \"Hello, this is a test.\"\n",
    "print(f\"Generating speech for: '{text}'\")\n",
    "print(\"Using: exaggeration=0.5, cfg_weight=0.5, temperature=1.0\")\n",
    "\n",
    "wav = model.generate(\n",
    "    text,\n",
    "    exaggeration=0.5,\n",
    "    cfg_weight=0.5,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "visualize_audio(wav, model.sr, \"Test 2: Simple Text (Your Params)\")\n",
    "print(\"\\nPlayback:\")\n",
    "play_audio(wav, model.sr)\n",
    "save_audio(wav, model.sr, \"test2_simple_your_params.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test 3: Check Model Parameters\n",
    "\n",
    "Let's check what parameters the model actually accepts and what the defaults are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the generate method\n",
    "import inspect\n",
    "\n",
    "signature = inspect.signature(model.generate)\n",
    "print(\"ChatterboxTurboTTS.generate() signature:\")\n",
    "print(signature)\n",
    "print(\"\\nParameters:\")\n",
    "for param_name, param in signature.parameters.items():\n",
    "    print(f\"  {param_name}: {param.annotation if param.annotation != inspect.Parameter.empty else 'Any'}\", end=\"\")\n",
    "    if param.default != inspect.Parameter.empty:\n",
    "        print(f\" = {param.default}\")\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test 4: Try Different Parameter Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test various parameter combinations\n",
    "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "param_tests = [\n",
    "    {\"name\": \"Default\", \"params\": {}},\n",
    "    {\"name\": \"Low exaggeration\", \"params\": {\"exaggeration\": 0.5}},\n",
    "    {\"name\": \"High exaggeration\", \"params\": {\"exaggeration\": 1.5}},\n",
    "    {\"name\": \"Low CFG\", \"params\": {\"cfg_weight\": 0.3}},\n",
    "    {\"name\": \"High CFG\", \"params\": {\"cfg_weight\": 0.9}},\n",
    "    {\"name\": \"Your params\", \"params\": {\"exaggeration\": 0.5, \"cfg_weight\": 0.5}},\n",
    "]\n",
    "\n",
    "for i, test in enumerate(param_tests, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Test {i}: {test['name']}\")\n",
    "    print(f\"Parameters: {test['params']}\")\n",
    "    \n",
    "    wav = model.generate(test_text, **test['params'])\n",
    "    \n",
    "    filename = f\"test4_params_{i}_{test['name'].replace(' ', '_').lower()}.wav\"\n",
    "    save_audio(wav, model.sr, filename)\n",
    "    \n",
    "    print(\"\\nPlayback:\")\n",
    "    play_audio(wav, model.sr)\n",
    "    \n",
    "    # Quick stats\n",
    "    wav_np = wav.cpu().numpy().squeeze() if isinstance(wav, torch.Tensor) else wav.squeeze()\n",
    "    print(f\"Duration: {len(wav_np) / model.sr:.2f}s, \"\n",
    "          f\"Amplitude range: [{wav_np.min():.3f}, {wav_np.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test 5: Your Preprocessed Sherlock Holmes Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "import re\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Preprocess text for better TTS quality.\"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "\n",
    "    for line in lines:\n",
    "        cleaned_line = line.strip()\n",
    "        if not cleaned_line:\n",
    "            if current_paragraph:\n",
    "                paragraphs.append(' '.join(current_paragraph))\n",
    "                current_paragraph = []\n",
    "        else:\n",
    "            current_paragraph.append(cleaned_line)\n",
    "\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(' '.join(current_paragraph))\n",
    "\n",
    "    result = '\\n\\n'.join(paragraphs)\n",
    "    result = re.sub(r' +', ' ', result)\n",
    "    return result\n",
    "\n",
    "print(\"✓ Preprocessing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Sherlock Holmes text (with formatting issues)\n",
    "raw_text = \"\"\"We loitered the morning away in the garden. Stanley Hopkins had\n",
    "      gone down to the village to look into some rumours of a strange\n",
    "      woman who had been seen by some children on the Chatham Road the\n",
    "      previous morning. As to my friend, all his usual energy seemed to\n",
    "      have deserted him. I had never known him handle a case in such a\n",
    "      half-hearted fashion. Even the news brought back by Hopkins that\n",
    "      he had found the children, and that they had undoubtedly seen a\n",
    "      woman exactly corresponding with Holmes's description, and\n",
    "      wearing either spectacles or eyeglasses, failed to rouse any sign\n",
    "      of keen interest. He was more attentive when Susan, who waited\n",
    "      upon us at lunch, volunteered the information that she believed\n",
    "      Mr. Smith had been out for a walk yesterday morning, and that he\n",
    "      had only returned half an hour before the tragedy occurred. I\n",
    "      could not myself see the bearing of this incident, but I clearly\n",
    "      perceived that Holmes was weaving it into the general scheme\n",
    "      which he had formed in his brain. Suddenly he sprang from his\n",
    "      chair and glanced at his watch. "Two o'clock, gentlemen," said\n",
    "      he. "We must go up and have it out with our friend, the\n",
    "      professor."\"\"\"\n",
    "\n",
    "# Preprocess it\n",
    "cleaned_text = preprocess_text(raw_text)\n",
    "\n",
    "print(\"Original text (first 200 chars):\")\n",
    "print(repr(raw_text[:200]))\n",
    "print(\"\\nCleaned text (first 200 chars):\")\n",
    "print(repr(cleaned_text[:200]))\n",
    "print(f\"\\nOriginal length: {len(raw_text)} chars\")\n",
    "print(f\"Cleaned length: {len(cleaned_text)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate with cleaned text using your parameters\n",
    "print(\"Generating with CLEANED text...\")\n",
    "print(f\"Text: {cleaned_text[:100]}...\")\n",
    "print(\"Parameters: exaggeration=0.5, cfg_weight=0.5, temperature=1.0\")\n",
    "\n",
    "wav_cleaned = model.generate(\n",
    "    cleaned_text,\n",
    "    exaggeration=0.5,\n",
    "    cfg_weight=0.5,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "visualize_audio(wav_cleaned, model.sr, \"Test 5: Sherlock (Cleaned)\")\n",
    "print(\"\\nPlayback:\")\n",
    "play_audio(wav_cleaned, model.sr)\n",
    "save_audio(wav_cleaned, model.sr, \"test5_sherlock_cleaned.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate with RAW text (to compare)\n",
    "print(\"Generating with RAW text (for comparison)...\")\n",
    "print(f\"Text: {raw_text[:100]}...\")\n",
    "print(\"Parameters: exaggeration=0.5, cfg_weight=0.5, temperature=1.0\")\n",
    "\n",
    "wav_raw = model.generate(\n",
    "    raw_text,\n",
    "    exaggeration=0.5,\n",
    "    cfg_weight=0.5,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "visualize_audio(wav_raw, model.sr, \"Test 5b: Sherlock (Raw)\")\n",
    "print(\"\\nPlayback:\")\n",
    "play_audio(wav_raw, model.sr)\n",
    "save_audio(wav_raw, model.sr, \"test5b_sherlock_raw.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test 6: Very Short Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with very short, clear sentences\n",
    "short_tests = [\n",
    "    \"Hello.\",\n",
    "    \"This is a test.\",\n",
    "    \"The weather is nice today.\",\n",
    "    \"I am testing the text to speech system.\",\n",
    "]\n",
    "\n",
    "for i, text in enumerate(short_tests, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Short test {i}: '{text}'\")\n",
    "    \n",
    "    wav = model.generate(\n",
    "        text,\n",
    "        exaggeration=0.5,\n",
    "        cfg_weight=0.5,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    \n",
    "    filename = f\"test6_short_{i}.wav\"\n",
    "    save_audio(wav, model.sr, filename)\n",
    "    \n",
    "    print(\"Playback:\")\n",
    "    play_audio(wav, model.sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Diagnostic Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nQuestions to answer:\")\n",
    "print(\"\\n1. Does Test 1 (simple text, default params) sound good?\")\n",
    "print(\"   → If YES: Default parameters work fine\")\n",
    "print(\"   → If NO: Model itself may have issues\")\n",
    "print(\"\\n2. Does Test 2 (simple text, your params) sound good?\")\n",
    "print(\"   → If YES: Your parameters are fine\")\n",
    "print(\"   → If NO: exaggeration=0.5, cfg_weight=0.5 may be too low\")\n",
    "print(\"\\n3. Which parameter combination in Test 4 sounds best?\")\n",
    "print(\"   → Use those parameters going forward\")\n",
    "print(\"\\n4. Does Test 5 (Sherlock cleaned) sound better than 5b (Sherlock raw)?\")\n",
    "print(\"   → If YES: Preprocessing is helping\")\n",
    "print(\"   → If NO: Preprocessing may not be the issue\")\n",
    "print(\"\\n5. Do the short sentences in Test 6 sound clear?\")\n",
    "print(\"   → If YES but long text is gibberish: May be text length issue\")\n",
    "print(\"   → If NO: Check audio output device/playback\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All test files saved. Download them and compare!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Download All Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated files\n",
    "import os\n",
    "import glob\n",
    "\n",
    "wav_files = glob.glob(\"test*.wav\")\n",
    "print(f\"Generated {len(wav_files)} test files:\")\n",
    "for f in sorted(wav_files):\n",
    "    size = os.path.getsize(f) / 1024  # KB\n",
    "    print(f\"  {f} ({size:.1f} KB)\")\n",
    "\n",
    "print(\"\\nOn Google Colab, you can download files from the file browser on the left.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Additional Debug: Check if Turbo Model is Actually Different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with standard Chatterbox (if available)\n",
    "try:\n",
    "    from chatterbox.tts import ChatterboxTTS\n",
    "    \n",
    "    print(\"Loading STANDARD Chatterbox model for comparison...\")\n",
    "    standard_model = ChatterboxTTS.from_pretrained(device=device)\n",
    "    print(f\"✓ Standard model loaded\")\n",
    "    print(f\"Standard model sample rate: {standard_model.sr} Hz\")\n",
    "    \n",
    "    # Test same text with both models\n",
    "    test_text = \"Hello, this is a comparison test.\"\n",
    "    \n",
    "    print(\"\\nGenerating with STANDARD model...\")\n",
    "    wav_standard = standard_model.generate(\n",
    "        test_text,\n",
    "        exaggeration=0.5,\n",
    "        cfg_weight=0.5,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    save_audio(wav_standard, standard_model.sr, \"comparison_standard.wav\")\n",
    "    print(\"Playback (Standard):\")\n",
    "    play_audio(wav_standard, standard_model.sr)\n",
    "    \n",
    "    print(\"\\nGenerating with TURBO model...\")\n",
    "    wav_turbo = model.generate(\n",
    "        test_text,\n",
    "        exaggeration=0.5,\n",
    "        cfg_weight=0.5,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    save_audio(wav_turbo, model.sr, \"comparison_turbo.wav\")\n",
    "    print(\"Playback (Turbo):\")\n",
    "    play_audio(wav_turbo, model.sr)\n",
    "    \n",
    "    print(\"\\nCompare the two outputs above!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Standard Chatterbox model not available in this package version.\")\n",
    "    print(\"Only Turbo model will be tested.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
